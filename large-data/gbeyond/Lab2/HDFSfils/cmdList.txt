本命令列表为Lab02 easy版的

修改本文件内容：
noden = 节点n名称;nodenip = 节点n IP 地址;nodeniip = 节点n内网IP;
node1 = 节点1名称;node1ip = 节点1 IP 地址;node1iip = 节点1内网IP;
node2 = 节点2名称;node2ip = 节点2 IP 地址;node2iip = 节点2内网IP;
node3 = 节点3名称;node3ip = 节点3 IP 地址;node3iip = 节点3内网IP;
node4 = 节点4名称;node4ip = 节点4 IP 地址;node4iip = 节点4内网IP;

开始实验：

修改文件
修改文件名： `mapred-site.xml.template` 改为 `mapred-site.xml`

修改文件内容：
文件均在 `hadoop-2.7.7/etc/hadoop/` 目录下
`hadoop-env.sh` : 添加配置文本 `export JAVA_HOME=/usr/lib/jvm/jdk8u292-b10` 到文件中
`core-site.xml` : 替换掉原文件中的 `<configuration></configuration>` 部分， 主要改fs.defaultFS、fs.obs.access.key、fs.obs.secret.key、fs.obs.endpoint
`hdfs-site.xml` : 替换掉原文件中的 `<configuration></configuration>` 部分，主要将node 名称改成自己实际的 node 名
`yarn-site.xml` : 替换掉原文件中的 `<configuration></configuration>` 部分，主要将node 名称改成自己实际的 node 名
`mapred-site.xml` : 替换掉原文件中的 `<configuration></configuration>` 部分，主要将node 名称改成自己实际的 node 名
`slaves` :原内容删除，改为子节点名称，共三行，文件内容如下
node2
node3
node4

# 本机
C:\Windows\System32\drivers\etc 下改hosts文件，添加以下内容
node1ip  node1
node2ip  node2
node3ip  node3
node4ip  node4

华为云安全组开放8020和50010端口

ssh root@node1ip #登录指令
# On node1~node4 respectively
vim /etc/hosts #编辑hosts文件，加入 node1~node4 对应 IP 及 node 节点名
node1iip  node1
node2iip  node2
node3iip  node3
node4iip  node4

node1iip  node1 node1
# Only on node1
systemctl status firewalld.service #查看防火墙状态
systemctl stop firewalld.service #关闭防火墙 .service
systemctl disable firewalld.service #禁止firewall开机启动 .service
# On node1~node4 respectively
ssh-keygen -t rsa #生成rsa类型的ssh密钥,用于远程免密登录，结果：生成/root/.ssh/id_rsa.pub
cat /root/.ssh/id_rsa.pub #输出文件内容，便于汇总
# 将4个节点的 id_rsa.pub 文件内容复制汇总到一个文件里，再分别拷到4个节点的 authorized_keys 中
vim /root/.ssh/authorized_keys #编辑 authorized_keys 文件，拷贝汇总的rsa密钥, 带前面的 "ssh-rsa "
ssh node1 #1->1
ssh node2 #1->2
ssh node2 #2->2
ssh node3 #2->3
ssh node3 #3->3
ssh node4 #3->4
ssh node4 #4->4
ssh node3 #4->3
ssh node2 #3->2
ssh node1 #2->1
ssh node3 #1->3
ssh node1 #3->1
ssh node4 #1->4
ssh node2 #4->2
ssh node4 #2->4
ssh node1 #4->1

# On my computer
# sftp 版
sftp root@node1ip
lcd Filepath
lpwd # 检查本机路径是否正确
put -r hadoop-2.7.7 hadoop-2.7.7 #不加后面会把文件内容散开传到root，第二个参数用/hadoop-2.7.7会传到根目录，用~/hadoop-2.7.7会不识别，如果目录下没有这个文件夹，会自动创建
put OpenJDK8U-jdk_aarch64_linux_openj9_8u292b10_openj9-0.26.0.tar
exit

# On node1
cp OpenJDK8U-jdk_aarch64_linux_openj9_8u292b10_openj9-0.26.0.tar /usr/lib/jvm/ #将 jdk 安装包拷贝到/usr/lib/jvm 目录下
scp /usr/lib/jvm/OpenJDK8U-jdk_aarch64_linux_openj9_8u292b10_openj9-0.26.0.tar root@node2:/usr/lib/jvm/ #分发安装包到节点2
scp /usr/lib/jvm/OpenJDK8U-jdk_aarch64_linux_openj9_8u292b10_openj9-0.26.0.tar root@node3:/usr/lib/jvm/ #分发安装包到节点3
scp /usr/lib/jvm/OpenJDK8U-jdk_aarch64_linux_openj9_8u292b10_openj9-0.26.0.tar root@node4:/usr/lib/jvm/ #分发安装包到节点4
# On node1~node4 respectively
cd /usr/lib/jvm/
tar -vxf OpenJDK8U-jdk_aarch64_linux_openj9_8u292b10_openj9-0.26.0.tar # 安装tar包

# On node1~node4 respectively
mkdir /home/modules/
# 确保他节点的/home/modules下没有hadoop-2.7.7文件夹，如有，rm -rf /home/modules/hadoop-2.7.7, 注意传过去别散开
cp -r hadoop-2.7.7 /home/modules/ #复制 hadoop 安装包，一定要确认复制完成后有没有hadoop-2.7.7文件夹
# scp 不行了用 sftp
scp -r /home/modules/hadoop-2.7.7 root@node2:/home/modules/hadoop-2.7.7 #分发Hadoop到节点2
scp -r /home/modules/hadoop-2.7.7 root@node3:/home/modules/hadoop-2.7.7 #分发Hadoop到节点3
scp -r /home/modules/hadoop-2.7.7 root@node4:/home/modules/hadoop-2.7.7 #分发Hadoop到节点4

# On node1~node4 respectively
vim /etc/profile #添加配置文本,内容如下
export JAVA_HOME=/usr/lib/jvm/jdk8u292-b10
export HADOOP_HOME=/home/modules/hadoop-2.7.7
export PATH=$JAVA_HOME/bin:$PATH
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
export HADOOP_CLASSPATH=/home/modules/hadoop-2.7.7/share/hadoop/tools/lib/*:$HADOOP_CLASSPATH
# On node1~node4 respectively
source /etc/profile #读取和执行 /etc/profile 文件。使配置生效
java -version #查看java版本

# On node1
hadoop namenode -format #格式化指令，使hadoop配置文件生效
chmod -R 777 /home/modules/hadoop-2.7.7 #修改文件权限，如果有Permission Denied就执行，没有就不用
# On node1
start-all.sh #启动 Hadoop
jps #验证,结果如下则正确
# On node2~node4 respectively
jps
# On node1
netstat -ltpn #查看端口
# On node1~node4 respectively
vim /etc/hosts #修改 hosts 文件
service network restart
# 或
/etc/init.d/network restart
# On node1
hadoop fs -ls / #浏览hadoop的文件系统，若目录下无文件则只会有一个 WARN 的提示后显示结束
hadoop dfsadmin -report #应该有三个子节点的状态信息
